{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f360e067-3a1d-44ac-a83f-234bf274aeac",
   "metadata": {},
   "source": [
    "(unsupervised_learning)=\n",
    "# Unsupervised Learning\n",
    "\n",
    "Unsupervised learning differs from [supervised learning](supervised_learning) in that it uses unlabeled data.\n",
    "Labeling data must usually be done manually by humans, and this can be both time-consuming and expensive.\n",
    "On the other hand, the labels provide information for the machine learning algorithm to learn from.\n",
    "Without labels, we can't do classification since there are no classes to learn.\n",
    "Instead, unsupervised learning looks for patterns in the data itself.\n",
    "\n",
    "The unsupervised alternative to classification is *clustering*, where we group similar items together in *clusters*.\n",
    "Clustering also requires vectorizing the data to get a numeric representation that the computer can work with.\n",
    "Unsupervised learning, like clustering, can be a good alternative when we lack the resources to label our data set."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2d02e23-5466-4b92-9340-f8eb1caa992d",
   "metadata": {},
   "source": [
    "## Visualizing Clustering\n",
    "\n",
    "Like with classification, we can visualize clustering to see what's happening.\n",
    "Again, we use a simple, simulated data set with only two features, so that the data can be plotted in a diagram."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e2946bb-a37b-498f-b127-24d4f79c6564",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.cluster import KMeans\n",
    "# configure matplotlib\n",
    "%config InlineBackend.figure_formats = ['svg']\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "326d4a26-04ae-4b98-916c-75addc150c57",
   "metadata": {},
   "source": [
    "Then, we use sklearn to make a simulated or synthetic data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0755110f-252f-430d-9574-0caf492fb926",
   "metadata": {},
   "outputs": [],
   "source": [
    "data, _ = make_classification(n_features=2, n_redundant=0, n_informative=2,\n",
    "                              random_state=2, n_clusters_per_class=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c04efed-7a25-488a-b50b-7218e3506799",
   "metadata": {},
   "source": [
    "We can plot the unlabeled data points in a scatter plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36e06434-8417-4342-9c16-5cd9c1d02113",
   "metadata": {},
   "outputs": [],
   "source": [
    "figure = plt.figure(figsize=(6, 6))\n",
    "plt.axis('equal')\n",
    "plt.scatter(data[:, 0], data[:, 1], marker='+');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14f92a2d-fad4-44d5-9b5f-705b165a9fca",
   "metadata": {},
   "source": [
    "Now, let's try to cluster the data with *k-means clustering*.\n",
    "k-means clustering is a common clustering algorithm.\n",
    "It takes the parameter *k*, which specifies the number of clusters we want to find.\n",
    "In other words, we must know in advance how many clusters we wish to look for.\n",
    "We can of course try different values for k, to see which works better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f29e5b0-fd40-4a59-b048-cacd699ee709",
   "metadata": {},
   "outputs": [],
   "source": [
    "Kmean = KMeans(n_clusters=2)\n",
    "Kmean.fit(data)\n",
    "clusters = Kmean.predict(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d41faf1a-7b19-4f83-a199-bb214e092d2d",
   "metadata": {},
   "source": [
    "We can plot the results of the clustering.\n",
    "What the algorithm learns is the mean or *center* of each cluster, which are displayed as blue dots on the plot.\n",
    "Each data item is assigned to the cluster center which is closest to it.\n",
    "The data points are colored according to their cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1994cb6c-3100-4003-9783-a7f7627f5943",
   "metadata": {},
   "outputs": [],
   "source": [
    "figure = plt.figure(figsize=(6, 6))\n",
    "plt.axis('equal')\n",
    "plt.scatter(data[:, 0], data[:, 1], c=clusters, marker='+', cmap=plt.cm.Set1)\n",
    "for cluster_x, cluster_y in Kmean.cluster_centers_:\n",
    "    plt.scatter(cluster_x, cluster_y, c='b')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ac3f118-db6a-4a07-920d-401d8ed3c125",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Clustering Text\n",
    "We can cluster text as well.\n",
    "The data preparation is much the same as we did when classifying texts.\n",
    "However, this time we will use the somewhat more powerful `TfidfVectorizer` instead of `CountVectorizer`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e030e6c-6ab0-4e57-8136-ec11591cafc9",
   "metadata": {
    "tags": [
     "hide-cell"
    ]
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def read_json_file(filename):\n",
    "    'Read json data from a file'\n",
    "    with open(filename, 'r') as file:\n",
    "        text_data = file.read()\n",
    "        return json.loads(text_data)\n",
    "\n",
    "\n",
    "def json_to_text(doc, include_headings=True):\n",
    "    '''\n",
    "    Extract content text from JSON tree structure.\n",
    "    https://echr-opendata.eu/doc/\n",
    "\n",
    "    Params:\n",
    "        doc: ECHR JSON element\n",
    "        include_headings: Whether to include the section headings\n",
    "    '''\n",
    "    def json_to_text_helper(doc):\n",
    "        result = []\n",
    "        if not doc['elements'] or include_headings:\n",
    "            result.append(doc['content'].strip().replace('\\xa0', ' '))  # replace non-breaking space\n",
    "        for element in doc['elements']:\n",
    "            result.extend(json_to_text_helper(element))\n",
    "        return result\n",
    "    return '\\n'.join(json_to_text_helper(doc))\n",
    "\n",
    "\n",
    "def get_facts(case):\n",
    "    'Get the \"Facts\" section of the case text'\n",
    "    content = case['content']\n",
    "    docname = list(content)[0]\n",
    "    document = content[docname]\n",
    "\n",
    "    for section in document:\n",
    "        if section.get('section_name') == 'facts':\n",
    "            return json_to_text(section)\n",
    "    return ''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2437e6fb-28ce-45a9-ae78-2660f2daef52",
   "metadata": {},
   "source": [
    "As before , we read the json data from the file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04d22167-f7fd-43b7-9cbd-51a59d931158",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cases = read_json_file('cases-2000.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "debf5021-b6a4-49a0-970c-3bd5dac4e555",
   "metadata": {},
   "source": [
    "This time, there is only one list which contains the documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f35719db-394b-4bb1-be3f-fe62abf1a5b2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "documents = [get_facts(case) for case in cases]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e3bc004-22a0-4fa0-bda7-8b91e29aa35b",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Vectorizing Text\n",
    "\n",
    "To use text documents in machine learning, they must first be vectorized.\n",
    "We'll use a TF-IDF representation, which is provided by scikit-learn's `TfidfVectorizer()`.\n",
    "This function has some parameters:\n",
    "- `stop_words='english'` means that *function words* like \"the\" and \"in\" should be ignored.\n",
    "Stop words carry little meaning, so it is often best to ignore them.\n",
    "This is done by using a dictionary of English stop words to ignore.\n",
    "- `lowercase=True` means that all words are converted to lowercase.\n",
    "If we don't do this, all the words at the start of sentences with capital letters will be treated as separate words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9d0861b-7f19-4809-b151-2b31bc9ffc65",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "text_vectorizer = TfidfVectorizer(\n",
    "    stop_words='english',\n",
    "    lowercase=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "478f20ba-27ce-4d11-a330-0790223f2cd7",
   "metadata": {
    "tags": []
   },
   "source": [
    "```{admonition} TF-IDF representation\n",
    ":class: dropdown\n",
    "`TfidfVectorizer` uses *TF-IDF* representation.\n",
    "TF is short for \"term frequency\", which is what `CountVectorizer` uses.\n",
    "IDF is short for \"inverse document frequency\", and measures how rare a word is in all the texts.\n",
    "A word that only occurs in a single document, is given more weight because it is probably more characteristic of that document.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d13c4521-bcfa-4391-92af-224c5b4f8f24",
   "metadata": {},
   "source": [
    "With the vectorizer made, we can use it to transform the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "056c77ee-f225-4a62-a9ff-e272fecfa383",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "input_features = text_vectorizer.fit_transform(documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "951e7738-c8f1-4b82-a3c0-277e4dc90d9e",
   "metadata": {},
   "source": [
    "Then we make the k-means clustering model.\n",
    "We need to select a value for k.\n",
    "If we don't know how many clusters to expect, we can just pick a number and see how that works.\n",
    "We try with 10 clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f92e9488-21f0-4c60-a45b-6c93697c42e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "K = 10\n",
    "kmeans = KMeans(n_clusters=K)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4852476-8559-4315-bd4b-b853c808c09b",
   "metadata": {},
   "source": [
    "Then we use the model to do the clustering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e35e9fb0-4845-43f8-b096-8a2718551064",
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters = kmeans.fit_predict(input_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d14f1306-441c-4dd3-a43c-6b99cef50b60",
   "metadata": {},
   "source": [
    "This method returns a list of cluster numbers, one for each document.\n",
    "We can use this to list the clusters.\n",
    "However, this is just a list of documents.\n",
    "Instead, let's try to describe the clusters.\n",
    "We can look at the terms that occur frequently in the cluster's documents."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "770fec7e-0db3-415b-9478-4f92dcb0f973",
   "metadata": {},
   "source": [
    "## Labeling Clusters\n",
    "Each cluster is represented by its center vector, which is called a centroid.\n",
    "We can use this vector to find terms that have a high TF-IDF value.\n",
    "These are terms that occur frequently in the documents in the cluster.\n",
    "\n",
    "We can get the list of the terms (the dictionary) from the vectorizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67722a67-0d74-4f93-aff7-d661e23f28a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "terms = text_vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccb89a38-e6bf-48b3-ae4d-c96d4f52a1f7",
   "metadata": {},
   "source": [
    "We can use the function `argsort()` to get a list of term indexes sorted from lowest to highest TF-IDF value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b63f160-c7d5-42d3-a918-72ecf8081327",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_terms_per_center = kmeans.cluster_centers_.argsort()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b350aa0-6221-4b93-940d-b2b231043ae5",
   "metadata": {},
   "source": [
    "Then we reverse the order, to get the items with the highest TF-IDF values first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6f8e69a-9a8f-49cc-9e7d-ca5f22fe0e28",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_terms_per_center = top_terms_per_center[:, ::-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8b40966-edf7-4b22-aee1-46529f93fe65",
   "metadata": {},
   "source": [
    "Then, we make a list of the ten terms with the highest TF-IDF values for each cluster.\n",
    "We do this by looking up the indexes in the term list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a07e6a9b-95f6-4f8b-b874-803ea5649a39",
   "metadata": {},
   "outputs": [],
   "source": [
    "for cluster in range(K):\n",
    "    print(f'cluster {cluster}: ', end='')\n",
    "    for index in top_terms_per_center[cluster, :10]:\n",
    "        print(terms[index], end=' ')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4519a4cc-ad54-4d4d-a808-996149c3ad05",
   "metadata": {},
   "source": [
    "Some of the terms aren't very informative.\n",
    "For example, the term \"applicant(s)\" appearing all the lists, and other terms also appear in many of them.\n",
    "We might get more informative labels by filtering out words that appear in more than two of the lists.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5adf4c38-a18c-4a38-8762-2a6824ca8817",
   "metadata": {},
   "source": [
    "## Applying Unsupervised Learning\n",
    "\n",
    "There are many possible applications for unsupervised learning.\n",
    "The list below has only a few examples."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e04d561-801a-46c7-9850-51977b65b6bc",
   "metadata": {},
   "source": [
    "### Organizing Document Collections\n",
    "Clustering is useful for organizing and navigating large document collections.\n",
    "Small collections may be organized by hand, but organizing large collections manually might be infeasible.\n",
    "\n",
    "### Search Result Diversification\n",
    "Terms in search queries are often ambiguous.\n",
    "For example, if someone searches for \"properties law\", do they mean \"property law\" or \"properties of law\", i.e. attributes of law?\n",
    "Clustering of search results can be used to make sure that both meanings are reflected in the search results.\n",
    "\n",
    "### Topic Modeling\n",
    "Topic modeling is another unsupervised learning method, somewhat related to clustering.\n",
    "The task is to discover a set of topics in a document collection.\n",
    "These topics are then used to label and organize the documents.\n",
    "\n",
    "### Visualizing Data\n",
    "Clustering is a useful tool for visualizing patterns in data.\n",
    "Another technique that might be necessary is *dimensionality reduction*.\n",
    "This reduces the number of features or dimensions of a data set.\n",
    "By extracting the most significant dimensions, the data can be visualized in 2 or 3 dimensions."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
