{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f1b0f5c9-8070-44b8-b1ea-c0a337d373ce",
   "metadata": {},
   "source": [
    "# Retrieval-Augmented Generation\n",
    "Retrieval-Augmented Generation (RAG) is a method for including (parts of) matching documents as context for questions to a large language model (LLM).\n",
    "This can help reduce hallucinations and wrong answers.\n",
    "A system for RAG has two parts: a document database with a search index and a large language model.\n",
    "\n",
    "When the user asks a question, the question is handled in two stages.\n",
    "First, the question is used as a search query for the document database.\n",
    "The search results are then sent together with the question to the LLM.\n",
    "The LLM is prompted to answer the question based on the context in the search results.\n",
    "\n",
    "We will use [LangChain](https://www.langchain.com/), an open-source library for making applications with LLMs.\n",
    "This chapter was inspired by the article\n",
    "[Retrieval-Augmented Generation (RAG) with open-source Hugging Face LLMs using LangChain](\n",
    "https://medium.com/@jiangan0808/retrieval-augmented-generation-rag-with-open-source-hugging-face-llms-using-langchain-bd618371be9d)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "198a041d",
   "metadata": {},
   "source": [
    "## Installing Software\n",
    "We’ll need to install some libraries first:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f9908a60",
   "metadata": {
    "editable": true,
    "scrolled": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: sentence-transformers in ./.local/lib/python3.11/site-packages (3.0.1)\n",
      "Requirement already satisfied: huggingface-hub in ./.local/lib/python3.11/site-packages (0.24.6)\n",
      "Requirement already satisfied: faiss-cpu in ./.local/lib/python3.11/site-packages (1.8.0.post1)\n",
      "Requirement already satisfied: sentencepiece in ./.local/lib/python3.11/site-packages (0.2.0)\n",
      "Requirement already satisfied: protobuf in ./.local/lib/python3.11/site-packages (5.28.0)\n",
      "Requirement already satisfied: langchain in ./.local/lib/python3.11/site-packages (0.2.15)\n",
      "Requirement already satisfied: langchain-community in ./.local/lib/python3.11/site-packages (0.2.15)\n",
      "Collecting pypdf\n",
      "  Downloading pypdf-4.3.1-py3-none-any.whl (295 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m295.8/295.8 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: transformers<5.0.0,>=4.34.0 in ./.local/lib/python3.11/site-packages (from sentence-transformers) (4.44.2)\n",
      "Requirement already satisfied: tqdm in ./.local/lib/python3.11/site-packages (from sentence-transformers) (4.66.5)\n",
      "Requirement already satisfied: torch>=1.11.0 in ./.local/lib/python3.11/site-packages (from sentence-transformers) (2.4.0)\n",
      "Requirement already satisfied: numpy in ./.local/lib/python3.11/site-packages (from sentence-transformers) (1.26.4)\n",
      "Requirement already satisfied: scikit-learn in ./.local/lib/python3.11/site-packages (from sentence-transformers) (1.5.1)\n",
      "Requirement already satisfied: scipy in ./.local/lib/python3.11/site-packages (from sentence-transformers) (1.14.1)\n",
      "Requirement already satisfied: Pillow in ./.local/lib/python3.11/site-packages (from sentence-transformers) (10.4.0)\n",
      "Requirement already satisfied: filelock in /cluster/software/EL9/easybuild/software/Python-bundle-PyPI/2023.06-GCCcore-12.3.0/lib/python3.11/site-packages (from huggingface-hub) (3.12.2)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /cluster/software/EL9/easybuild/software/Python-bundle-PyPI/2023.06-GCCcore-12.3.0/lib/python3.11/site-packages (from huggingface-hub) (2023.6.0)\n",
      "Requirement already satisfied: packaging>=20.9 in /cluster/software/EL9/easybuild/software/hatchling/1.18.0-GCCcore-12.3.0/lib/python3.11/site-packages (from huggingface-hub) (23.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /cluster/software/EL9/easybuild/software/PyYAML/6.0-GCCcore-12.3.0/lib/python3.11/site-packages (from huggingface-hub) (6.0)\n",
      "Requirement already satisfied: requests in /cluster/software/EL9/easybuild/software/Python-bundle-PyPI/2023.06-GCCcore-12.3.0/lib/python3.11/site-packages (from huggingface-hub) (2.31.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /cluster/software/EL9/easybuild/software/hatchling/1.18.0-GCCcore-12.3.0/lib/python3.11/site-packages (from huggingface-hub) (4.6.3)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in ./.local/lib/python3.11/site-packages (from langchain) (2.0.32)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in ./.local/lib/python3.11/site-packages (from langchain) (3.10.5)\n",
      "Requirement already satisfied: langchain-core<0.3.0,>=0.2.35 in ./.local/lib/python3.11/site-packages (from langchain) (0.2.37)\n",
      "Requirement already satisfied: langchain-text-splitters<0.3.0,>=0.2.0 in ./.local/lib/python3.11/site-packages (from langchain) (0.2.2)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in ./.local/lib/python3.11/site-packages (from langchain) (0.1.108)\n",
      "Requirement already satisfied: pydantic<3,>=1 in ./.local/lib/python3.11/site-packages (from langchain) (2.8.2)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in ./.local/lib/python3.11/site-packages (from langchain) (8.5.0)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in ./.local/lib/python3.11/site-packages (from langchain-community) (0.6.7)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in ./.local/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in ./.local/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /cluster/software/EL9/easybuild/software/Python-bundle-PyPI/2023.06-GCCcore-12.3.0/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in ./.local/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in ./.local/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in ./.local/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.5)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in ./.local/lib/python3.11/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (3.22.0)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in ./.local/lib/python3.11/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (0.9.0)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in ./.local/lib/python3.11/site-packages (from langchain-core<0.3.0,>=0.2.35->langchain) (1.33)\n",
      "Collecting packaging>=20.9 (from huggingface-hub)\n",
      "  Using cached packaging-24.1-py3-none-any.whl (53 kB)\n",
      "Collecting typing-extensions>=3.7.4.3 (from huggingface-hub)\n",
      "  Using cached typing_extensions-4.12.2-py3-none-any.whl (37 kB)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in ./.local/lib/python3.11/site-packages (from langsmith<0.2.0,>=0.1.17->langchain) (0.27.2)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in ./.local/lib/python3.11/site-packages (from langsmith<0.2.0,>=0.1.17->langchain) (3.10.7)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in ./.local/lib/python3.11/site-packages (from pydantic<3,>=1->langchain) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.20.1 in ./.local/lib/python3.11/site-packages (from pydantic<3,>=1->langchain) (2.20.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /cluster/software/EL9/easybuild/software/Python-bundle-PyPI/2023.06-GCCcore-12.3.0/lib/python3.11/site-packages (from requests->huggingface-hub) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /cluster/software/EL9/easybuild/software/Python-bundle-PyPI/2023.06-GCCcore-12.3.0/lib/python3.11/site-packages (from requests->huggingface-hub) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /cluster/software/EL9/easybuild/software/Python-bundle-PyPI/2023.06-GCCcore-12.3.0/lib/python3.11/site-packages (from requests->huggingface-hub) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /cluster/software/EL9/easybuild/software/Python-bundle-PyPI/2023.06-GCCcore-12.3.0/lib/python3.11/site-packages (from requests->huggingface-hub) (2023.5.7)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in ./.local/lib/python3.11/site-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.3)\n",
      "Requirement already satisfied: sympy in ./.local/lib/python3.11/site-packages (from torch>=1.11.0->sentence-transformers) (1.13.2)\n",
      "Requirement already satisfied: networkx in ./.local/lib/python3.11/site-packages (from torch>=1.11.0->sentence-transformers) (3.3)\n",
      "Requirement already satisfied: jinja2 in /cluster/software/EL9/easybuild/software/Python-bundle-PyPI/2023.06-GCCcore-12.3.0/lib/python3.11/site-packages (from torch>=1.11.0->sentence-transformers) (3.1.2)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in ./.local/lib/python3.11/site-packages (from torch>=1.11.0->sentence-transformers) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in ./.local/lib/python3.11/site-packages (from torch>=1.11.0->sentence-transformers) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in ./.local/lib/python3.11/site-packages (from torch>=1.11.0->sentence-transformers) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in ./.local/lib/python3.11/site-packages (from torch>=1.11.0->sentence-transformers) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in ./.local/lib/python3.11/site-packages (from torch>=1.11.0->sentence-transformers) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in ./.local/lib/python3.11/site-packages (from torch>=1.11.0->sentence-transformers) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in ./.local/lib/python3.11/site-packages (from torch>=1.11.0->sentence-transformers) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in ./.local/lib/python3.11/site-packages (from torch>=1.11.0->sentence-transformers) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in ./.local/lib/python3.11/site-packages (from torch>=1.11.0->sentence-transformers) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in ./.local/lib/python3.11/site-packages (from torch>=1.11.0->sentence-transformers) (2.20.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in ./.local/lib/python3.11/site-packages (from torch>=1.11.0->sentence-transformers) (12.1.105)\n",
      "Requirement already satisfied: triton==3.0.0 in ./.local/lib/python3.11/site-packages (from torch>=1.11.0->sentence-transformers) (3.0.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in ./.local/lib/python3.11/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.11.0->sentence-transformers) (12.6.68)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /cluster/software/EL9/easybuild/software/Python-bundle-PyPI/2023.06-GCCcore-12.3.0/lib/python3.11/site-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers) (2023.6.3)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in ./.local/lib/python3.11/site-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers) (0.4.4)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in ./.local/lib/python3.11/site-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers) (0.19.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /cluster/software/EL9/easybuild/software/Python-bundle-PyPI/2023.06-GCCcore-12.3.0/lib/python3.11/site-packages (from scikit-learn->sentence-transformers) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /cluster/software/EL9/easybuild/software/Python-bundle-PyPI/2023.06-GCCcore-12.3.0/lib/python3.11/site-packages (from scikit-learn->sentence-transformers) (3.1.0)\n",
      "Requirement already satisfied: anyio in /cluster/software/EL9/easybuild/software/jupyter-server/2.7.2-GCCcore-12.3.0/lib/python3.11/site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (3.7.1)\n",
      "Requirement already satisfied: httpcore==1.* in ./.local/lib/python3.11/site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (1.0.5)\n",
      "Requirement already satisfied: sniffio in /cluster/software/EL9/easybuild/software/jupyter-server/2.7.2-GCCcore-12.3.0/lib/python3.11/site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (1.3.0)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in ./.local/lib/python3.11/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in ./.local/lib/python3.11/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.35->langchain) (3.0.0)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in ./.local/lib/python3.11/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community) (1.0.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /cluster/software/EL9/easybuild/software/Python-bundle-PyPI/2023.06-GCCcore-12.3.0/lib/python3.11/site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (2.1.3)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in ./.local/lib/python3.11/site-packages (from sympy->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
      "Installing collected packages: typing-extensions, pypdf, packaging\n",
      "Successfully installed packaging-24.1 pypdf-4.3.1 typing-extensions-4.12.2\n",
      "\u001b[33mWARNING: There was an error checking the latest version of pip.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "#run to install required libraries:\n",
    "!pip install --upgrade sentence-transformers huggingface-hub faiss-cpu sentencepiece protobuf langchain langchain-community pypdf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62855d10-417b-4648-a14e-f5512c1f4f18",
   "metadata": {},
   "source": [
    "## The Language Model\n",
    "We’ll use models from [HuggingFace](https://huggingface.co/), a website that has tools and models for machine learning.\n",
    "We’ll use the open-source LLM [mistralai/Mistral-Nemo-Instruct-2407]( https://huggingface.co/mistralai/Mistral-Nemo-Instruct-2407).\n",
    "This model has 12 billion parameters.\n",
    "For comparison, one of the largest LLMs at the time of writing is Llama 3.1, with 405 billion parameters.\n",
    "Still, Mistral-Nemo-Instruct is around 25 GB, which makes it a quite large model.\n",
    "To run it, we must have a GPU with at least 25 GB memory.\n",
    "It can also be run without a GPU, but that will be much slower."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ac38b664-7075-4ed6-9a21-bb1465b7c095",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: HF_HOME=/cluster/work/projects/ec12/ewinge/cache/\n"
     ]
    }
   ],
   "source": [
    "%env HF_HOME=/cluster/work/projects/ec12/ewinge/cache/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bd74d3d-d6b3-422e-ba7f-160036830e38",
   "metadata": {},
   "source": [
    "Even though the model Mistral-Nemo-Instruct-2407 is open source, we must log in to HuggingFace to download it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "40a0f096-4213-4fad-8930-efb3b2a74c54",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "remove-output"
    ]
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d48a5b94d10f4ea99c7d748541edfda4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from huggingface_hub import login\n",
    "login()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fb595bd",
   "metadata": {},
   "source": [
    "To use the model, we create a *pipeline*.\n",
    "A pipeline can consist of several processing steps, but in this case, we only need one step.\n",
    "We can use the method `HuggingFacePipeline.from_model_id()`, which automatically downloads the specified model from HuggingFace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "35c9a472-a34d-418d-a129-971b987fb023",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b68f2b483ade4cf38e2e81a091332d91",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from langchain_community.llms import HuggingFacePipeline\n",
    "\n",
    "llm = HuggingFacePipeline.from_model_id(\n",
    "    model_id='mistralai/Mistral-Nemo-Instruct-2407',\n",
    "    task='text-generation',\n",
    "    device=0,\n",
    "    pipeline_kwargs={\n",
    "        'max_new_tokens': 300,\n",
    "        'temperature': 0.3,\n",
    "        'num_beams': 4,\n",
    "        'do_sample': True\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42032173",
   "metadata": {},
   "source": [
    "```{admonition} Pipeline Arguments\n",
    "We give some arguments to the pipeline:\n",
    "- `model_id`: the name of the  model on HuggingFace\n",
    "- `task`:  the task you want to use the model for,  other alternatives are  translation and summarization\n",
    "- `device`: the GPU hardware device to use. If we don't specify a device, no GPU will be used.\n",
    "- `pipeline_kwargs`: additional parameters that are passed to the model.\n",
    "    - `max_new_tokens`: maximum length of the generated text\n",
    "    - `do_sample`: by default, the most likely next word is chosen.  This makes the output deterministic. We can introduce some randomness by sampling among the  most likely words instead.\n",
    "    - `temperature`: the temperature controls the amount of randomness, where zero means no randomness.\n",
    "    - `num_beams`: by default the model works with a single sequence of  tokens/words. With beam search, the program  builds multiple sequences at the same time, and then selects the best one in the end.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "729d0038",
   "metadata": {},
   "source": [
    "## Using the language model\n",
    "Now, the language model is ready to use.\n",
    "Let’s try to use only the language model without RAG.\n",
    "We can send it a query:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a8b8608c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "what are the main problems with bitcoin? Bitcoin has several challenges and criticisms, including:\n",
      "\n",
      "1. **Volatility**: Bitcoin's price is highly volatile, making it less suitable as a medium of exchange for everyday transactions. Its value can fluctuate significantly over short periods, which can make it difficult to use for purchasing goods and services.\n",
      "\n",
      "2. **Scalability**: Bitcoin's network can only process a limited number of transactions per second (around 7), which can lead to slower transaction times and higher fees during periods of heavy usage. This is often referred to as the \"block size debate.\"\n",
      "\n",
      "3. **Energy Consumption**: Bitcoin's proof-of-work (PoW) consensus mechanism requires a large amount of energy to secure the network. This has led to concerns about its environmental impact. Some estimates suggest that Bitcoin's energy consumption is comparable to that of entire countries.\n",
      "\n",
      "4. **Regulation**: Bitcoin's decentralized nature makes it difficult for governments to regulate. While this is often seen as a strength, it also means that there's no central authority to protect users if something goes wrong. This has led to concerns about consumer protection and money laundering.\n",
      "\n",
      "5. **Security**: While Bitcoin's blockchain is secure, individual users' bitcoins can be stolen or lost if they don't properly secure their private keys. There have also been instances of exchanges being hacked, leading to significant losses for users.\n",
      "\n",
      "6. **Adoption**: For Bitcoin to become a widely used currency, it needs to be adopted by a large number of people\n"
     ]
    }
   ],
   "source": [
    "query = 'what are the main problems with bitcoin?'\n",
    "output = llm.invoke(query)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0c68fab",
   "metadata": {},
   "source": [
    "This answer was generated based only on the information contained in the language model.\n",
    "To improve the accuracy of the answer, we can provide the language model with additional context for our query.\n",
    "To do that, we must load our document collection.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5c6b933",
   "metadata": {},
   "source": [
    "## The Vectorizer\n",
    "Text must be [vectorized](vectorizing) before it can be processed.\n",
    "Our HuggingFace pipeline will do that automatically for the large language model.\n",
    "But we must make a vectorizer for the search index for our documents database.\n",
    "We use a vectorizer called a word embedding model from HuggingFace.\n",
    "Again, the HuggingFace library will automatically download the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5cbff637-d938-445d-b769-a2122ded10f7",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain_community.embeddings import HuggingFaceBgeEmbeddings\n",
    "\n",
    "huggingface_embeddings = HuggingFaceBgeEmbeddings(\n",
    "    model_name='BAAI/bge-m3',\n",
    "    model_kwargs = {'device': 'cuda:0'},\n",
    "    #or: model_kwargs={'device':'cpu'},\n",
    "    encode_kwargs={'normalize_embeddings': True}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afcde34e",
   "metadata": {},
   "source": [
    "```{admonition} Embeddings Arguments\n",
    "These are the arguments to the embedding model:\n",
    "- 'model_name': the name of the model on HuggingFace\n",
    "- 'device':  the hardware device to use, either a GPU or CPU\n",
    "- 'normalize_embeddings':  embeddings can have different magnitudes. Normalizing the embeddings makes their magnitudes equal.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78cccc3c",
   "metadata": {},
   "source": [
    "## Loading the Documents\n",
    "We use a document loader from the LangChain library\n",
    "to load all the PDFs in the  folder called  `documents`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b2c93ac6-1f9d-4cfb-a91d-606ff65930d0",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "remove-output"
    ]
   },
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import PyPDFDirectoryLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4a2716c7",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "#from langchain_community.document_loaders import DirectoryLoader\n",
    "#loader = DirectoryLoader('./documents/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4ee6a7f5",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "remove-output"
    ]
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ignoring wrong pointing object 13 0 (offset 0)\n",
      "Ignoring wrong pointing object 29 0 (offset 0)\n",
      "Ignoring wrong pointing object 35 0 (offset 0)\n",
      "Ignoring wrong pointing object 43 0 (offset 0)\n",
      "Ignoring wrong pointing object 112 0 (offset 0)\n",
      "Ignoring wrong pointing object 137 0 (offset 0)\n",
      "Ignoring wrong pointing object 148 0 (offset 0)\n"
     ]
    }
   ],
   "source": [
    "loader = PyPDFDirectoryLoader('./documents/')\n",
    "docs = loader.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59c25011",
   "metadata": {},
   "source": [
    "The document loader loads each PDF page as a separate 'document'.\n",
    "This is partly for technical reasons because that is the way PDFs are structured.\n",
    "But we would want to split our documents into smaller chunks anyway.\n",
    "We can check how long our documents are. \n",
    "First, we define a function for this:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d6c379dc-1ea3-4cf1-b46c-26af57d109f6",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import statistics\n",
    "def average_length(documents):\n",
    "    return statistics.fmean([len(doc.page_content) for doc in documents])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e0ccc63",
   "metadata": {},
   "source": [
    "Now, we can use this function on our documents:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e14fb549-406c-44d0-9977-eaa29fb2645f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of documents: 291, average document length: 2077\n",
      "Maximum document length:  9821\n"
     ]
    }
   ],
   "source": [
    "print(f'Number of documents: {len(docs)}, average document length: {int(average_length(docs))}')\n",
    "print('Maximum document length: ', max([len(doc.page_content) for doc in docs]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edb87be6",
   "metadata": {},
   "source": [
    "We can examine one of the documents:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4ca436e9-389c-44b1-9b9c-22639b32fdef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page_content='Local guide to BibL ATEX\n",
      "Knut Hegna, Dag Langmyhr\n",
      "19th September 2020' metadata={'source': 'documents/biblatex-guide.pdf', 'page': 0}\n"
     ]
    }
   ],
   "source": [
    "print(docs[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e77bd50",
   "metadata": {},
   "source": [
    "## Splitting the Documents\n",
    "Since we are only using PDFs with quite short pages, we can use them as they are.\n",
    "Other, longer documents, for example the documents or webpages, we might need to split into chunks. \n",
    "We can use a text splitter from LangChain to split documents.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "94a25aff-8375-4ced-9e97-99a004bdca47",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size = 5000, #  or less, like 700 for models with smaller context windows\n",
    "    chunk_overlap  = 100,\n",
    ")\n",
    "docs = text_splitter.split_documents(docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e75424e3-137e-425f-95a9-7fc9f9f1b984",
   "metadata": {},
   "source": [
    "```{admonition} Text  Splitter Arguments\n",
    "These are the arguments to the text splitter:\n",
    "- 'chunk_size': the number of tokens in each chunk.  Not necessarily the same as the number of words.\n",
    "- 'chunk_overlap': the number of tokens that are included in both chunks where the text is split.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ac8df41",
   "metadata": {},
   "source": [
    "We can check if the average and maximum document length has changed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1a2b8845-4e0e-4b41-bdc6-c5b60aaaad86",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of documents: 301, average document length: 2010\n",
      "Maximum document length:  4989\n"
     ]
    }
   ],
   "source": [
    "print(f'Number of documents: {len(docs)}, average document length: {int(average_length(docs))}')\n",
    "print('Maximum document length: ', max([len(doc.page_content) for doc in docs]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0b35b55a-3e96-4352-bf5a-5156bb1b5fe7",
   "metadata": {
    "editable": true,
    "scrolled": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of the embedding:  (1024,)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "sample_embedding = np.array(huggingface_embeddings.embed_query(docs[0].page_content))\n",
    "#print('Sample embedding of a document chunk: ', sample_embedding)\n",
    "print('Size of the embedding: ', sample_embedding.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6f9b6bb",
   "metadata": {},
   "source": [
    "## The Document Index\n",
    "Next, we make a search index for our documents.\n",
    "We will use this index for the retrieval part of 'Retrieval-Augmented Generation'.\n",
    "We use the open-source library [FAISS](https://github.com/facebookresearch/faiss)\n",
    "(Facebook AI Similarity Search) through LangChain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "efb25e38-750d-490d-be4a-c15e6d789167",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores import FAISS\n",
    "vectorstore = FAISS.from_documents(docs, huggingface_embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dcdf4cd",
   "metadata": {},
   "source": [
    "FAISS can find documents that match a search query:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6f5a7369-9690-4f13-84d2-2112d6da2e44",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of documents found: 4\n"
     ]
    }
   ],
   "source": [
    "query = 'what are the main problems with bitcoin?'\n",
    "relevant_documents = vectorstore.similarity_search(query)\n",
    "print(f'Number of documents found: {len(relevant_documents)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e8a6f10-1912-428d-b793-023a75bfcdd4",
   "metadata": {},
   "source": [
    "We can display the first document:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e094fb4f-9337-43f6-86d6-1a5920a8bb9e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yale Information Society Project 8 8 problems. Thefts, bugs, and other problems can be undone if detected in time. Cryptocurrencies lack this critical feature. This is why cryptocurrency thefts, as a fraction of the available currency, are orders of magnitude more common and severe than thefts in the normal financial system.  The largest significant electronic bank heist, targeting the Bank of Bangladesh, managed to steal roughly $100 million.8 Cryptocurrency hacks of similar magnitude are almost a monthly occurrence; indeed, in the largest cryptocurrency hack on record, of Axie Infinity’s “Ronin Bridge,” hackers stole over $600 million.9 This ease of theft is inherent in the very nature of cryptocurrency. Stealing $10 million in physical cash requires that someone break into a secure location and move 100 kilograms of physical paper. Stealing $10 million in a traditional bank transfer requires both breaking into the bank’s computer and also quickly moving the money through a series of accounts to hide its origin, such that the victim’s bank cannot undo the theft. Stealing $10 million in cryptocurrency controlled by a computer, on the other hand, requires compromising the computer but—critically—the victim can’t recover the money.10 This creates significant friction in buying cryptocurrencies. Someone who wishes to sell cryptocurrencies cannot accept a conventional electronic payment. Instead they either have to have an established relationship with the buyer (to know the buyer poses an acceptable credit risk), accept cash, or accept an electronic payment and then wait for a few days.11 This drives up the price of buying cryptocurrency as all three options (validating credit risk, accepting cache, or waiting) incur additional expenses not present in other payment systems. Furthermore, the actual cryptocurrency transactions themselves can be surprisingly expensive.12 In order to act as a limit on spam transactions, where someone creates a huge number of useless transitions that need to be validated, slowing down the transaction verification process, any given cryptocurrency allows only a limited number of transactions per block in the blockchain. When the desired number of transactions is below this threshold, transactions are nearly free. But if the desired transaction rate exceeds this threshold, then prices can spiral as a fee auction is used to select which transactions to process due to the inelastic supply of available slots.\n"
     ]
    }
   ],
   "source": [
    "print(relevant_documents[0].page_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9957ab6b",
   "metadata": {},
   "source": [
    "For our RAG application we need to access the search engine through an interface called a retriever:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "15c6b860-1146-4256-8aad-5dd5cc245f8e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "retriever = vectorstore.as_retriever(search_kwargs={'k': 3})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a03857d",
   "metadata": {},
   "source": [
    "```{admonition} Retriever Arguments\n",
    "These are the arguments to the retriever:\n",
    "- 'k': the number of documents to return (kNN search)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1e788a2",
   "metadata": {},
   "source": [
    "## Making a Prompt\n",
    "We can use a *prompt* to tell the language model how to answer.\n",
    "The prompt should contain a few short, helpful instructions.\n",
    "In addition, we provide placeholders for the context and the question.\n",
    "LangChain replaces these with the actual context and question when we execute a query.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c55f5c61-e016-4c26-9038-b063516835ab",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "prompt_template = '''You are an assistant for question-answering tasks.\n",
    "Use the following pieces of retrieved context to answer the question.\n",
    "If you don't know the answer, just say that you don't know.\n",
    "Keep the answer concise.\n",
    "Context: {context}\n",
    "\n",
    "Question: {input}\n",
    "\n",
    "Answer:\n",
    "'''\n",
    "\n",
    "prompt = PromptTemplate(template=prompt_template,\n",
    "                        input_variables=['context', 'input'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe6ed759",
   "metadata": {},
   "source": [
    "## Making the «Chatbot»\n",
    "Now we can use the module `create_retrieval_chain` from LangChain to make an agent for answering questions, a «chatbot».\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b65fec1c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from langchain.chains import create_retrieval_chain\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "\n",
    "combine_docs_chain = create_stuff_documents_chain(llm, prompt)\n",
    "rag_chain = create_retrieval_chain(retriever, combine_docs_chain)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b61b425",
   "metadata": {},
   "source": [
    "## Asking the «Chatbot»\n",
    "Now, we can send our query to the chatbot.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0a4a29f4-d1da-4934-9229-1905613a38ed",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "scroll-output"
    ]
   },
   "outputs": [],
   "source": [
    "result = rag_chain.invoke({'input': query})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c22798b8-2bad-4a0b-b9a7-01f365890514",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "scroll-output"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are an assistant for question-answering tasks.\n",
      "Use the following pieces of retrieved context to answer the question.\n",
      "If you don't know the answer, just say that you don't know.\n",
      "Keep the answer concise.\n",
      "Context: Yale Information Society Project 8 8 problems. Thefts, bugs, and other problems can be undone if detected in time. Cryptocurrencies lack this critical feature. This is why cryptocurrency thefts, as a fraction of the available currency, are orders of magnitude more common and severe than thefts in the normal financial system.  The largest significant electronic bank heist, targeting the Bank of Bangladesh, managed to steal roughly $100 million.8 Cryptocurrency hacks of similar magnitude are almost a monthly occurrence; indeed, in the largest cryptocurrency hack on record, of Axie Infinity’s “Ronin Bridge,” hackers stole over $600 million.9 This ease of theft is inherent in the very nature of cryptocurrency. Stealing $10 million in physical cash requires that someone break into a secure location and move 100 kilograms of physical paper. Stealing $10 million in a traditional bank transfer requires both breaking into the bank’s computer and also quickly moving the money through a series of accounts to hide its origin, such that the victim’s bank cannot undo the theft. Stealing $10 million in cryptocurrency controlled by a computer, on the other hand, requires compromising the computer but—critically—the victim can’t recover the money.10 This creates significant friction in buying cryptocurrencies. Someone who wishes to sell cryptocurrencies cannot accept a conventional electronic payment. Instead they either have to have an established relationship with the buyer (to know the buyer poses an acceptable credit risk), accept cash, or accept an electronic payment and then wait for a few days.11 This drives up the price of buying cryptocurrency as all three options (validating credit risk, accepting cache, or waiting) incur additional expenses not present in other payment systems. Furthermore, the actual cryptocurrency transactions themselves can be surprisingly expensive.12 In order to act as a limit on spam transactions, where someone creates a huge number of useless transitions that need to be validated, slowing down the transaction verification process, any given cryptocurrency allows only a limited number of transactions per block in the blockchain. When the desired number of transactions is below this threshold, transactions are nearly free. But if the desired transaction rate exceeds this threshold, then prices can spiral as a fee auction is used to select which transactions to process due to the inelastic supply of available slots.\n",
      "\n",
      "JUNE 2018  |   VOL. 61  |   NO. 6  |   COMMUNICATIONS OF THE ACM    23viewpoints\n",
      "This was not because our Bitcoin \n",
      "was stolen from a honeypot, rather the \n",
      "graduate student who created the wallet \n",
      "maintained a copy and his account was \n",
      "compromised. If security experts can’t \n",
      "safely keep cryptocurrencies on an Inter -\n",
      "net-connected computer, nobody can. If \n",
      "Bitcoin is the “Internet of money,” what \n",
      "does it say that it cannot be safely stored \n",
      "on an Internet connected computer?\n",
      "Bugs can also naturally cause sig-\n",
      "nificant damage to cryptocurrency \n",
      "holdings. Although this potentially can \n",
      "affect any cryptocurrency, the biggest \n",
      "danger for bugs arises when cryptocur-\n",
      "rencies are combined with “smart con-\n",
      "tracts”—programs that are generally \n",
      "immutable once deployed and that au-\n",
      "tomatically execute upon the transfer \n",
      "of currency. The most successful plat-\n",
      "form for these is Ethereum, a crypto-\n",
      "currency that allows writing programs \n",
      "in a language called Solidity.\n",
      "Bugs in these smart contracts can \n",
      "be catastrophic. The first big smart \n",
      "contract, the DAO or Decentralized Au -\n",
      "tonomous Organization, sought to cre -\n",
      "ate a democratic mutual fund where \n",
      "investors could invest their Ethereum \n",
      "and then vote on possible investments. \n",
      "Approximately 10% of all Ethereum \n",
      "ended up in the DAO before someone \n",
      "discovered a reentrancy bug that en -\n",
      "abled the attacker to effectively steal all \n",
      "the Ethereum. The only reason this bug \n",
      "and theft did not result in global losses \n",
      "is that Ethereum developers released a \n",
      "new version of the system that effective -\n",
      "ly undid the theft by altering the sup -\n",
      "posedly immutable blockchain.\n",
      "Since then there have been other \n",
      "catastrophic bugs in these smart con-\n",
      "tracts, the biggest one in the Parity \n",
      "Ethereum wallet software (see https://\n",
      "bit.ly/2Fm7je4). The first bug enabled \n",
      "the mass theft from “multisignature” \n",
      "wallets, which supposedly required \n",
      "multiple independent cryptographic \n",
      "signatures on transfers as a way to pre-\n",
      "vent theft. Fortunately, that bug caused \n",
      "limited damage because a good thief \n",
      "stole most of the money and then re-\n",
      "turned it to the victims. Yet, the good \n",
      "news was limited as a subsequent bug \n",
      "rendered all of the new multisignature \n",
      "wallets permanently inaccessible, ef-\n",
      "fectively destroying some $150M in no-\n",
      "tional value. This buggy code was large-\n",
      "ly written by Gavin Wood, the creator \n",
      "of the Solidity programming language and one of the founders of Ethereum. \n",
      "Again, we have a situation where even \n",
      "an expert’s efforts fell short.\n",
      "Individual Economic Risks\n",
      "Everything about the cryptocurrency \n",
      "space is full of bubbles. Since all volatile \n",
      "cryptocurrencies are actually substan -\n",
      "tially inferior for legal purposes, this im -\n",
      "plies that the actual value as currency is \n",
      "effectively $0, so the only store of value \n",
      "is in other utility for a distributed trust -\n",
      "less public append-only ledger.\n",
      "Yet the Bitcoin blockchain, due to \n",
      "consolidation of mining into a few min -\n",
      "ing pools, does not actually distribute \n",
      "trust. Instead the system is effectively \n",
      "controlled by less than 10 entities self-\n",
      "selected by their willingness to consume \n",
      "power and anyone using Bitcoin implic -\n",
      "itly trusts a majority of these few entities. \n",
      "Every proof of work blockchain seems to \n",
      "experience similar consolidation as the \n",
      "more efficient miners inevitably drive out \n",
      "less efficient ones. Given the almost trivial \n",
      "cost of building a three-transactions-per-\n",
      "second distributed system with identified \n",
      "and trusted entities using cryptographic \n",
      "signatures instead of proof of work this \n",
      "suggests the utility value for these cryp -\n",
      "tocurrencies is also effectively $0. This \n",
      "means everyone participating in the \n",
      "cryptocurrency market is basing the val -\n",
      "ue only on the price that somebody else \n",
      "will pay—no different from tulip bulbs or \n",
      "beanie babies—and are all vulnerable to \n",
      "substantial and sudden collapse .\n",
      "But further magnifying the prob-\n",
      "lem is a large number of scams. There \n",
      "is a current trend in “Initial Coin Of-\n",
      "ferings,” mostly consisting of crypto-\n",
      "graphic tokens implemented on top \n",
      "of an existing cryptocurrencies such as \n",
      "Bitcoin or Ethereum. Although claim-\n",
      "ing to be crowd-sold tokens for pur-\n",
      "chase of future services, the tradeable \n",
      "nature of these tokens has resulted in \n",
      "their acting as unregistered securities in a bubble market. There are also or-\n",
      "ganized groups conducting pump-and-\n",
      "dump schemes, complete with fancy \n",
      "websites, animated advertisements, \n",
      "and even placing paper advertisements \n",
      "in BART commuter trains in San Fran-\n",
      "cisco, CA. This market developed large-\n",
      "ly in absence of regulation, although \n",
      "regulators like the U.S. Securities and \n",
      "Exchange Commission are finally start-\n",
      "ing to pay attention.\n",
      "Likewise, not only is a bubble often \n",
      "a natural Ponzi scheme, there are many \n",
      "explicit or likely Ponzi schemes. In the \n",
      "early days of Bitcoin approximately 10% \n",
      "of all Bitcoin were invested in Bitcoin \n",
      "Savings and Trust, a Ponzi scheme run \n",
      "by a pseudonymous individual known\n",
      "\n",
      "The Death of Cryptocurrency | Nicholas Weaver 9 Bitcoin is particularly limited in this respect. Due to an early decision to limit spam by restricting the block size to just one megabyte, the Bitcoin network can only process somewhere between three and seven transactions per second worldwide. In comparison, the typical load on the VISA network is 1,700 transactions per second, and VISA has tested the system up to 64,000 transactions per second. During times of congestion, this can lead to the price for Bitcoin transactions reaching $50 or more. Other cryptocurrencies may have higher limits, which naturally leads them to be more vulnerable to spam. High congestion fees ensure that Bitcoin transactions can never be used for everyday, low-value payments. It is inconceivable that consumers would be willing to pay an extra $50 at the grocery store because they went shopping on a Saturday or Sunday afternoon. Cryptocurrency advocates will insist that “layer-two solutions” exist for this problem. They will often point to the Bitcoin “Lightning Network,” a protocol implemented on top of the underlying cryptocurrency, as an example of a solution. Unfortunately these don’t solve the fundamental problem of limited transaction capacity. Lightning works by creating a pre-funded payment channel between the user and a central relayer.13 From there the user can issue or receive payments that pass through a chain of relayers to the recipient. Eventually, a user may close the channel and receive the Bitcoin back onto the main blockchain. Thus, the internal payments no longer need to be recorded on the central blockchain. In creating, adding funds, and closing the channel, the user still needs to conduct a normal Bitcoin transaction. The Lightning network’s ability to create or close channels is limited by Bitcoin’s own transaction limitations. Therefore, Lightning cannot provide scaling as there is still a substantial limit on the number of channels that can be created, funded, or closed per second. The one example where Bitcoin did scale to a significant number of transactions was in El Salvador, though it scaled, ironically, by not actually using Bitcoin to process payments.14 The dictator of El Salvador, President Nayib Bukele, passed a law mandating that Bitcoin, along with the US dollar, would now be considered official currencies and merchants were\n",
      "\n",
      "Question: what are the main problems with bitcoin?\n",
      "\n",
      "Answer:\n",
      "- High risk of theft due to lack of undo feature\n",
      "- Expensive transactions, especially during congestion\n",
      "- Limited transaction capacity (3-7 transactions per second)\n",
      "- Centralization of mining power in few entities\n",
      "- High number of scams and Ponzi schemes\n",
      "- Bugs in smart contracts can lead to significant losses\n",
      "- Not suitable for everyday, low-value payments due to high fees\n"
     ]
    }
   ],
   "source": [
    "print(result['answer'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5c38ea6",
   "metadata": {},
   "source": [
    "This answer contains information about transaction fees from the context.\n",
    "This information wasn’t in the previous answer, when we queried only the language model without Retrieval-Augmented Generation."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
